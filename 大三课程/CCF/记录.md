这句话强调了在优化 RAG（Retrieval-Augmented Generation）流程时，应该重点关注以下几个环节：文本解析、文本切片、检索过滤和排序。以下是本文件代码中与这些环节相关的部分：

1. **文本解析**：
   - 代码中使用 `PyPDFDirectoryLoader` 解析 PDF 文档，并将其内容加载到内存中。
   - 示例代码：
     ```python
     loader = PyPDFDirectoryLoader(DOCS_DIR)
     pages = loader.load_and_split()
     ```

2. **文本切片**：
   - 使用 `RecursiveCharacterTextSplitter` 对文本进行切片，将长文本分割成较小的块，以便后续处理。
   - 示例代码：
     ```python
     text_splitter = RecursiveCharacterTextSplitter(
         chunk_size=300,
         chunk_overlap=100,
         separators=["。", "！", "？"],
         keep_separator='end',
     )
     docs = text_splitter.split_documents(documents)
     ```

3. **检索过滤**：
   - 使用 BM25 和密集向量检索器（Dense Retriever）进行检索，并结合两者的结果。
   - 示例代码：
     ```python
     dense_retriever = vectordb.as_retriever(search_kwargs={"k": 5})
     bm25_retriever = BM25Retriever.from_documents(
         docs,
         k=5,
         bm25_params={"k1": 1.6, "b": 0.75},
         preprocess_func=jieba.lcut
     )
     ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, dense_retriever], weights=[0.4, 0.6])
     ```

4. **排序**：
   - 使用 `CrossEncoderReranker` 对检索到的文档进行重排序，以提高相关性。
   - 示例代码：
     ```python
     def rerank(questions, retriever, top_n=1, cut_len=384):
         rerank_model = HuggingFaceCrossEncoder(model_name=RERANK_MODEL)
         compressor = CrossEncoderReranker(model=rerank_model, top_n=top_n)
         compression_retriever = ContextualCompressionRetriever(
             base_compressor=compressor, base_retriever=retriever
         )
         rerank_answers = []
         for question in tqdm(questions):
             relevant_docs = compression_retriever.invoke(question)
             answer = ''
             for rd in relevant_docs:
                 answer += rd.page_content
             rerank_answers.append(answer[:245])
         return rerank_answers
     ```

这些代码片段展示了如何解析文档、切片文本、进行检索和排序，以优化 RAG 流程。

## 评分
• **问题评分**
对于任意问题，采用如下公式评分：

**score 𝑖=[\*i\*=[ weight 𝑖𝑘𝑤×\*i\**k\**w\*× score 𝑖𝑘𝑤+(1−\*i\**k\**w\*+(1− weight 𝑖𝑘𝑤)×\*i\**k\**w\*)× score 𝑖𝑒𝑠]×𝑝𝑖\*i\**e\**s\*]×\*p\**i\***

**scoreikw**: 关键词评分。出题方为每题标注了若干答案关键词，选手提交文件的answer列中准确包含所有关键词得1分，包含部分关键词则按比例得分。
**scoreies** ：向量相似度评分。出题方为每题标注了答案所在文本块，根据选手提交文件中embedding列与标注文本块向量表示的余弦相似度打分，完全一致得1分。
**weightikw** ：关键词评分占总评分的权重。通常为0.1至0.9之间的权重，表格查数问题的关键词得分权重为1。
**pi**：长度惩罚项。根据选手 answer 的长度 𝑙𝑒𝑛𝑖𝑠𝑢𝑏*l**e**n**i**s**u**b*​ 与标注文本块长度 𝑙𝑒𝑛𝑖𝑠𝑡𝑑*l**e**n**i**s**t**d*​ 确定, 𝑙𝑒𝑛𝑖sub ≤1.5𝑙𝑒𝑛𝑖std *l**e**n**i*sub ​≤1.5*l**e**n**i*std ​ 时该项为 1;1.51;1.5 len 𝑖std <𝑙𝑒𝑛𝑖sub ≤2.5𝑙𝑒𝑛𝑖std *i*std ​<*l**e**n**i*sub ​≤2.5*l**e**n**i*std ​ 时该项为 0.9;0.9; 𝑙𝑒𝑛𝑖sub >2.5𝑙𝑒𝑛𝑖std *l**e**n**i*sub ​>2.5*l**e**n**i*std ​ 时该项为 0.75 。


## 发现

中国信息通信研究院地址：北京市海淀区花园北路52号邮政编码：100191联系电话：010-68094140传真：010-62304980网址：www.caict.ac.cn

这些数据貌似和提问无关，可以考虑进行文本剔除



有什么参数可以控制回答的长度，增强回答的准确度



数据